# MCP Server Configuration

# Environment (dev, staging, prod)
environment: "dev"

# AWS Service Configurations
aws:
  # RDS Aurora PostgreSQL Configuration
  rds:
    auth:
      region: "us-west-2"
    host: "your-aurora-cluster.cluster-xxxxxxxxx.us-west-2.rds.amazonaws.com"
    port: 5432
    database: "mcp"
    username: "mcp_admin"
    password: "" # Leave empty when using IAM authentication
    use_iam_auth: true # IAM authentication is the default and recommended method
    token_expiration: 900 # 15 minutes in seconds
    
    # Optimized connection pool settings for vector operations
    max_open_conns: 50  # Increased from 25 for better throughput
    max_idle_conns: 10  # Increased from 5 to reduce connection creation overhead
    conn_max_lifetime: 15m  # Increased from 5m to reduce reconnection frequency
    
    # Vector operation specific pool - separates vector queries from regular CRUD
    vector_pool:
      enabled: true
      max_open_conns: 25  # Dedicated connections for vector operations
      max_idle_conns: 5
      conn_max_lifetime: 10m
    
    enable_pooling: true
    min_pool_size: 5   # Increased from 2 to handle more concurrent requests
    max_pool_size: 20  # Increased from 10 for better scalability
    connection_timeout: 30
  
  # ElastiCache Redis Configuration
  elasticache:
    auth:
      region: "us-west-2"
    primary_endpoint: "your-redis-cluster.xxxxxx.clustercfg.usw2.cache.amazonaws.com"
    port: 6379
    username: "mcp_cache_user"
    password: "" # Leave empty when using IAM authentication
    use_iam_auth: true # IAM authentication is the default and recommended method
    cluster_mode: true
    cluster_name: "mcp-cache"
    cluster_discovery: true
    use_tls: true
    insecure_skip_verify: false # Set to true only for testing
    max_retries: 3
    
    # Optimized cache pool settings
    min_idle_connections: 5  # Increased from 2 to reduce connection creation overhead
    pool_size: 20  # Increased from 10 for better throughput
    dial_timeout: 5
    read_timeout: 3
    write_timeout: 3
    pool_timeout: 4
    token_expiration: 900 # 15 minutes in seconds
  
  # S3 Configuration for context storage
  s3:
    auth:
      region: "us-west-2"
    bucket: "mcp-contexts"
    use_iam_auth: true # IAM authentication is the default and recommended method
    server_side_encryption: "AES256"
    
    # Optimized S3 settings for large context data
    upload_part_size: 10485760  # 10MB (increased from 5MB)
    download_part_size: 10485760  # 10MB (increased from 5MB)
    concurrency: 10  # Increased from 5 for better throughput
    request_timeout: 60s  # Increased from 30s for large files

# Storage Configuration
storage:
  # Storage provider type: "s3" is recommended for production
  type: "s3"
  
  # Context Storage Configuration
  context_storage:
    provider: "s3" # "database" or "s3"
    s3_path_prefix: "contexts"
    
    # Embedding storage configuration
    embedding_storage:
      enable_preprocessing: true  # Enable vector normalization
      enable_caching: true  # Cache frequently accessed embeddings
      default_similarity_threshold: 0.75  # Default similarity threshold for search

# API Server Configuration
api:
  listen_address: ":8080" # For development; use ":443" for production
  read_timeout: 30s
  write_timeout: 30s
  idle_timeout: 60s
  enable_cors: true
  
  # TLS Configuration (required for production)
  # tls_cert_file: "/certs/tls.crt"
  # tls_key_file: "/certs/tls.key"
  
  # Authentication
  auth:
    jwt_secret: "change-this-to-a-secure-secret"
    api_keys:
      admin: "change-this-to-a-secure-api-key"
      reader: "change-this-to-a-different-secure-api-key"
  
  # Rate Limiting
  rate_limit:
    enabled: true
    limit: 100
    period: 1m
    burst_factor: 3
  
  # DevOps Tool Webhooks
  webhooks:
    github:
      enabled: true
      path: "/github"
      secret: "change-this-to-a-secure-webhook-secret"

# Database Configuration
database:
  driver: "postgres"
  dsn: "postgres://user:password@localhost:5432/mcp?sslmode=disable" # Used only if not using AWS RDS with IAM auth
  
  # Enhanced connection pool settings
  max_open_conns: 50
  max_idle_conns: 10
  conn_max_lifetime: 15m
  
  # PgVector specific optimizations
  vector:
    enabled: true
    index_type: "ivfflat"  # Options: "ivfflat", "hnsw"
    lists: 100  # Number of lists for ivfflat index
    probes: 10  # Number of probes for search (higher = more accurate but slower)
    
    # Separate connection pool for vector operations
    pool:
      enabled: true
      max_open_conns: 25
      max_idle_conns: 5
      conn_max_lifetime: 10m

# Cache Configuration
cache:
  type: "redis"
  address: "localhost:6379" # Used only if not using AWS ElastiCache
  password: ""
  db: 0
  
  # Enhanced cache pool settings
  pool_size: 20
  min_idle_conns: 5
  dial_timeout: 5s
  read_timeout: 3s
  write_timeout: 3s
  
  # Embedding cache settings
  embedding_cache:
    enabled: true
    ttl: 24h  # Time-to-live for cached embeddings
    max_items: 10000  # Maximum number of cached embeddings
    eviction_policy: "lru"  # Least recently used

# Core Engine Configuration
engine:
  event_buffer_size: 10000
  concurrency_limit: 10
  event_timeout: 30s
  
  # Security Settings
  security:
    safe_mode: true  # Enable safety checks for all operations
    audit_logging: true  # Log all adapter operations for audit purposes

# DevOps Tool Adapters
adapters:
  github:
    api_token: "your-github-api-token"
    webhook_secret: "your-github-webhook-secret"
    # enterprise_url: "https://github.yourdomain.com/api/v3" # For GitHub Enterprise
    request_timeout: 30s
    retry_max: 3
    retry_delay: 1s
    mock_responses: true
    mock_url: "http://mockserver:8081/mock-github"
  
  harness:
    api_token: "your-harness-api-token"
    account_id: "your-harness-account-id"
    org_identifier: "default"
    project_identifier: "your-project-id"
    base_url: "https://app.harness.io"
    api_url: "https://app.harness.io/ng/api"
    graphql_url: "https://app.harness.io/gateway/api/graphql"
    # CCM specific configurations
    ccm_api_url: "https://app.harness.io/ccm/api"
    ccm_graphql_url: "https://app.harness.io/ccm/graphql"
    # Request configuration
    request_timeout: 30s
    retry_max: 3
    retry_delay: 1s
    # Mock server settings for testing
    mock_responses: true
    mock_url: "http://mockserver:8081/mock-harness"
  
  sonarqube:
    base_url: "https://sonarqube.example.com/api"
    token: "your-sonarqube-token"
    # Or use username/password authentication
    # username: "your-sonarqube-username"
    # password: "your-sonarqube-password"
    request_timeout: 30s
    retry_max: 3
    retry_delay: 1s
    mock_responses: true
    mock_url: "http://mockserver:8081/mock-sonarqube"
  
  artifactory:
    base_url: "https://artifactory.example.com/artifactory/api"
    token: "your-artifactory-token"
    # Or use username/password authentication
    # username: "your-artifactory-username"
    # password: "your-artifactory-password"
    request_timeout: 30s
    retry_max: 3
    retry_delay: 1s
    mock_responses: true
    mock_url: "http://mockserver:8081/mock-artifactory"
  
  xray:
    base_url: "https://xray.example.com/api/v1"
    token: "your-xray-token"
    # Or use username/password authentication
    # username: "your-xray-username"
    # password: "your-xray-password"
    request_timeout: 30s
    retry_max: 3
    retry_delay: 1s
    mock_responses: true
    mock_url: "http://mockserver:8081/mock-xray"

# Monitoring Configuration
monitoring:
  prometheus:
    enabled: true
    path: "/metrics"
    # Vector search specific metrics
    vector_metrics:
      enabled: true
      collect_histograms: true
      percentiles: [0.5, 0.9, 0.95, 0.99]
  
  logging:
    level: "info"
    format: "json"
    output: "stdout"
    file_path: ""
