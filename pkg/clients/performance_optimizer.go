package clients

import (
	"bytes"
	"compress/gzip"
	"context"
	"fmt"
	"io"
	"net/http"
	"sync"
	"sync/atomic"
	"time"
	
	"github.com/developer-mesh/developer-mesh/pkg/observability"
)

// PerformanceOptimizer manages performance optimizations
type PerformanceOptimizer struct {
	mu     sync.RWMutex
	logger observability.Logger
	
	// Connection pool management
	poolManager *ConnectionPoolManager
	
	// Response compression
	compressionHandler *CompressionHandler
	
	// Load balancing
	loadBalancer *LoadBalancer
	
	// Performance metrics
	metrics *PerformanceMetrics
	
	// Configuration
	config OptimizationConfig
}

// OptimizationConfig defines performance optimization settings
type OptimizationConfig struct {
	// Connection pooling
	EnableDynamicPooling bool          `json:"enable_dynamic_pooling"`
	MinConnections       int           `json:"min_connections"`
	MaxConnections       int           `json:"max_connections"`
	ConnectionTTL        time.Duration `json:"connection_ttl"`
	
	// Compression
	EnableCompression  bool   `json:"enable_compression"`
	CompressionLevel   int    `json:"compression_level"`
	MinCompressionSize int    `json:"min_compression_size"`
	AcceptEncodings    string `json:"accept_encodings"`
	
	// Load balancing
	EnableLoadBalancing bool     `json:"enable_load_balancing"`
	Endpoints           []string `json:"endpoints"`
	BalancingStrategy   string   `json:"balancing_strategy"` // round-robin, least-connections, weighted
	
	// Performance tuning
	EnableHTTP2         bool          `json:"enable_http2"`
	EnableKeepAlive     bool          `json:"enable_keep_alive"`
	KeepAliveTimeout    time.Duration `json:"keep_alive_timeout"`
	ResponseTimeout     time.Duration `json:"response_timeout"`
	MaxIdleConnsPerHost int           `json:"max_idle_conns_per_host"`
}

// ConnectionPoolManager manages dynamic connection pooling
type ConnectionPoolManager struct {
	mu sync.RWMutex
	
	// Pool configuration
	minConns       int
	maxConns       int
	currentConns   int32
	activeConns    int32
	
	// Connection tracking
	connections    map[string]*PooledConnection
	connMutex      sync.RWMutex
	
	// Pool statistics
	totalRequests  int64
	poolHits       int64
	poolMisses     int64
	avgWaitTime    time.Duration
	
	// Dynamic adjustment
	lastAdjustment time.Time
	adjustInterval time.Duration
}

// PooledConnection represents a pooled connection
type PooledConnection struct {
	ID           string
	Transport    *http.Transport
	CreatedAt    time.Time
	LastUsed     time.Time
	UseCount     int64
	InUse        bool
	HealthStatus string
}

// CompressionHandler handles response compression
type CompressionHandler struct {
	mu sync.RWMutex
	
	// Configuration
	level        int
	minSize      int
	acceptTypes  []string
	
	// Statistics
	totalCompressed   int64
	totalUncompressed int64
	bytesBeforeComp   int64
	bytesAfterComp    int64
	avgCompressionRatio float64
}

// LoadBalancer manages load distribution across endpoints
type LoadBalancer struct {
	mu sync.RWMutex
	
	// Endpoints
	endpoints      []*Endpoint
	currentIndex   int32
	
	// Strategy
	strategy       string
	
	// Health tracking
	healthChecker  *HealthChecker
}

// Endpoint represents a backend endpoint
type Endpoint struct {
	URL           string
	Weight        int
	Healthy       bool
	ActiveConns   int32
	TotalRequests int64
	AvgLatency    time.Duration
	LastCheck     time.Time
}

// HealthChecker monitors endpoint health
type HealthChecker struct {
	interval   time.Duration
	timeout    time.Duration
	endpoints  []*Endpoint
	shutdown   chan struct{}
	wg         sync.WaitGroup
}

// PerformanceMetrics tracks performance metrics
type PerformanceMetrics struct {
	mu sync.RWMutex
	
	// Connection metrics
	ConnectionsCreated   int64
	ConnectionsReused    int64
	ConnectionsClosed    int64
	AvgConnectionAge     time.Duration
	
	// Compression metrics
	CompressionRatio     float64
	CompressionTime      time.Duration
	DecompressionTime    time.Duration
	
	// Load balancing metrics
	RequestsDistributed  map[string]int64
	EndpointLatencies    map[string]time.Duration
	FailoverCount        int64
	
	// Overall performance
	AvgResponseTime      time.Duration
	P95ResponseTime      time.Duration
	P99ResponseTime      time.Duration
	Throughput           float64
}

// DefaultOptimizationConfig returns default optimization configuration
func DefaultOptimizationConfig() OptimizationConfig {
	return OptimizationConfig{
		EnableDynamicPooling: true,
		MinConnections:       10,
		MaxConnections:       100,
		ConnectionTTL:        5 * time.Minute,
		EnableCompression:    true,
		CompressionLevel:     gzip.DefaultCompression,
		MinCompressionSize:   1024,
		AcceptEncodings:      "gzip, deflate",
		EnableLoadBalancing:  false,
		BalancingStrategy:    "round-robin",
		EnableHTTP2:          true,
		EnableKeepAlive:      true,
		KeepAliveTimeout:     30 * time.Second,
		ResponseTimeout:      30 * time.Second,
		MaxIdleConnsPerHost:  10,
	}
}

// NewPerformanceOptimizer creates a new performance optimizer
func NewPerformanceOptimizer(config OptimizationConfig, logger observability.Logger) *PerformanceOptimizer {
	optimizer := &PerformanceOptimizer{
		logger:  logger,
		config:  config,
		metrics: &PerformanceMetrics{
			RequestsDistributed: make(map[string]int64),
			EndpointLatencies:   make(map[string]time.Duration),
		},
	}
	
	// Initialize connection pool manager
	if config.EnableDynamicPooling {
		optimizer.poolManager = &ConnectionPoolManager{
			minConns:       config.MinConnections,
			maxConns:       config.MaxConnections,
			connections:    make(map[string]*PooledConnection),
			adjustInterval: 30 * time.Second,
		}
	}
	
	// Initialize compression handler
	if config.EnableCompression {
		optimizer.compressionHandler = &CompressionHandler{
			level:       config.CompressionLevel,
			minSize:     config.MinCompressionSize,
			acceptTypes: []string{"application/json", "text/plain", "text/html"},
		}
	}
	
	// Initialize load balancer
	if config.EnableLoadBalancing && len(config.Endpoints) > 0 {
		endpoints := make([]*Endpoint, len(config.Endpoints))
		for i, url := range config.Endpoints {
			endpoints[i] = &Endpoint{
				URL:     url,
				Weight:  1,
				Healthy: true,
			}
		}
		
		optimizer.loadBalancer = &LoadBalancer{
			endpoints: endpoints,
			strategy:  config.BalancingStrategy,
			healthChecker: &HealthChecker{
				interval:  30 * time.Second,
				timeout:   5 * time.Second,
				endpoints: endpoints,
				shutdown:  make(chan struct{}),
			},
		}
		
		// Start health checking
		optimizer.loadBalancer.healthChecker.Start()
	}
	
	return optimizer
}

// OptimizeTransport creates an optimized HTTP transport
func (o *PerformanceOptimizer) OptimizeTransport() *http.Transport {
	transport := &http.Transport{
		MaxIdleConns:        o.config.MaxConnections,
		MaxIdleConnsPerHost: o.config.MaxIdleConnsPerHost,
		IdleConnTimeout:     o.config.ConnectionTTL,
		DisableKeepAlives:   !o.config.EnableKeepAlive,
		ForceAttemptHTTP2:   o.config.EnableHTTP2,
		TLSHandshakeTimeout: 10 * time.Second,
		ResponseHeaderTimeout: o.config.ResponseTimeout,
	}
	
	// Add compression if enabled
	if o.config.EnableCompression {
		transport.DisableCompression = false
	}
	
	return transport
}

// GetConnection gets an optimized connection from the pool
func (o *PerformanceOptimizer) GetConnection(ctx context.Context) (*http.Transport, error) {
	if o.poolManager == nil {
		return o.OptimizeTransport(), nil
	}
	
	return o.poolManager.GetConnection(ctx)
}

// ReleaseConnection returns a connection to the pool
func (o *PerformanceOptimizer) ReleaseConnection(transport *http.Transport) {
	if o.poolManager != nil {
		o.poolManager.ReleaseConnection(transport)
	}
}

// CompressRequest compresses request body if beneficial
func (o *PerformanceOptimizer) CompressRequest(data []byte) ([]byte, string, error) {
	if o.compressionHandler == nil || len(data) < o.config.MinCompressionSize {
		return data, "", nil
	}
	
	return o.compressionHandler.Compress(data)
}

// DecompressResponse decompresses response body if needed
func (o *PerformanceOptimizer) DecompressResponse(data []byte, encoding string) ([]byte, error) {
	if o.compressionHandler == nil || encoding == "" {
		return data, nil
	}
	
	return o.compressionHandler.Decompress(data, encoding)
}

// SelectEndpoint selects an endpoint using load balancing
func (o *PerformanceOptimizer) SelectEndpoint() (string, error) {
	if o.loadBalancer == nil || len(o.loadBalancer.endpoints) == 0 {
		return "", fmt.Errorf("no endpoints available")
	}
	
	return o.loadBalancer.SelectEndpoint()
}

// ConnectionPoolManager methods

// GetConnection gets a connection from the pool
func (pm *ConnectionPoolManager) GetConnection(ctx context.Context) (*http.Transport, error) {
	pm.connMutex.Lock()
	defer pm.connMutex.Unlock()
	
	// Find an available connection
	for _, conn := range pm.connections {
		if !conn.InUse && conn.HealthStatus == "healthy" {
			conn.InUse = true
			conn.LastUsed = time.Now()
			conn.UseCount++
			atomic.AddInt32(&pm.activeConns, 1)
			atomic.AddInt64(&pm.poolHits, 1)
			
			return conn.Transport, nil
		}
	}
	
	// Create new connection if under limit
	currentConns := atomic.LoadInt32(&pm.currentConns)
	if currentConns < int32(pm.maxConns) {
		transport := &http.Transport{
			MaxIdleConns:        100,
			MaxIdleConnsPerHost: 10,
			IdleConnTimeout:     90 * time.Second,
		}
		
		conn := &PooledConnection{
			ID:           fmt.Sprintf("conn-%d", time.Now().UnixNano()),
			Transport:    transport,
			CreatedAt:    time.Now(),
			LastUsed:     time.Now(),
			UseCount:     1,
			InUse:        true,
			HealthStatus: "healthy",
		}
		
		pm.connections[conn.ID] = conn
		atomic.AddInt32(&pm.currentConns, 1)
		atomic.AddInt32(&pm.activeConns, 1)
		atomic.AddInt64(&pm.poolMisses, 1)
		
		return transport, nil
	}
	
	// Pool is full
	return nil, fmt.Errorf("connection pool exhausted")
}

// ReleaseConnection returns a connection to the pool
func (pm *ConnectionPoolManager) ReleaseConnection(transport *http.Transport) {
	pm.connMutex.Lock()
	defer pm.connMutex.Unlock()
	
	// Find the connection
	for _, conn := range pm.connections {
		if conn.Transport == transport {
			conn.InUse = false
			atomic.AddInt32(&pm.activeConns, -1)
			break
		}
	}
}

// CompressionHandler methods

// Compress compresses data using gzip
func (ch *CompressionHandler) Compress(data []byte) ([]byte, string, error) {
	startTime := time.Now()
	
	var buf bytes.Buffer
	gz := gzip.NewWriter(&buf)
	gz.Name = "data"
	gz.ModTime = time.Now()
	
	if _, err := gz.Write(data); err != nil {
		return nil, "", fmt.Errorf("compression failed: %w", err)
	}
	
	if err := gz.Close(); err != nil {
		return nil, "", fmt.Errorf("failed to close gzip writer: %w", err)
	}
	
	compressed := buf.Bytes()
	
	// Update statistics
	ch.mu.Lock()
	ch.totalCompressed++
	ch.bytesBeforeComp += int64(len(data))
	ch.bytesAfterComp += int64(len(compressed))
	ratio := float64(len(compressed)) / float64(len(data))
	if ch.avgCompressionRatio == 0 {
		ch.avgCompressionRatio = ratio
	} else {
		ch.avgCompressionRatio = (ch.avgCompressionRatio + ratio) / 2
	}
	ch.mu.Unlock()
	
	_ = time.Since(startTime) // Would record compression time
	
	return compressed, "gzip", nil
}

// Decompress decompresses data based on encoding
func (ch *CompressionHandler) Decompress(data []byte, encoding string) ([]byte, error) {
	startTime := time.Now()
	defer func() {
		_ = time.Since(startTime) // Would record decompression time
	}()
	
	switch encoding {
	case "gzip":
		reader, err := gzip.NewReader(bytes.NewReader(data))
		if err != nil {
			return nil, fmt.Errorf("failed to create gzip reader: %w", err)
		}
		defer reader.Close()
		
		decompressed, err := io.ReadAll(reader)
		if err != nil {
			return nil, fmt.Errorf("failed to decompress: %w", err)
		}
		
		ch.mu.Lock()
		ch.totalUncompressed++
		ch.mu.Unlock()
		
		return decompressed, nil
		
	default:
		return data, nil
	}
}

// LoadBalancer methods

// SelectEndpoint selects an endpoint based on strategy
func (lb *LoadBalancer) SelectEndpoint() (string, error) {
	lb.mu.Lock()
	defer lb.mu.Unlock()
	
	switch lb.strategy {
	case "round-robin":
		return lb.roundRobinSelect()
	case "least-connections":
		return lb.leastConnectionsSelect()
	case "weighted":
		return lb.weightedSelect()
	default:
		return lb.roundRobinSelect()
	}
}

// roundRobinSelect selects endpoint using round-robin
func (lb *LoadBalancer) roundRobinSelect() (string, error) {
	healthyEndpoints := make([]*Endpoint, 0)
	for _, ep := range lb.endpoints {
		if ep.Healthy {
			healthyEndpoints = append(healthyEndpoints, ep)
		}
	}
	
	if len(healthyEndpoints) == 0 {
		return "", fmt.Errorf("no healthy endpoints available")
	}
	
	index := atomic.AddInt32(&lb.currentIndex, 1) % int32(len(healthyEndpoints))
	endpoint := healthyEndpoints[index]
	
	atomic.AddInt32(&endpoint.ActiveConns, 1)
	atomic.AddInt64(&endpoint.TotalRequests, 1)
	
	return endpoint.URL, nil
}

// leastConnectionsSelect selects endpoint with least connections
func (lb *LoadBalancer) leastConnectionsSelect() (string, error) {
	var selected *Endpoint
	minConns := int32(^uint32(0) >> 1) // Max int32
	
	for _, ep := range lb.endpoints {
		if ep.Healthy && ep.ActiveConns < minConns {
			selected = ep
			minConns = ep.ActiveConns
		}
	}
	
	if selected == nil {
		return "", fmt.Errorf("no healthy endpoints available")
	}
	
	atomic.AddInt32(&selected.ActiveConns, 1)
	atomic.AddInt64(&selected.TotalRequests, 1)
	
	return selected.URL, nil
}

// weightedSelect selects endpoint based on weights
func (lb *LoadBalancer) weightedSelect() (string, error) {
	// Simple weighted selection
	// Could be enhanced with more sophisticated algorithms
	return lb.roundRobinSelect()
}

// HealthChecker methods

// Start begins health checking
func (hc *HealthChecker) Start() {
	hc.wg.Add(1)
	go hc.checkLoop()
}

// checkLoop performs periodic health checks
func (hc *HealthChecker) checkLoop() {
	defer hc.wg.Done()
	
	ticker := time.NewTicker(hc.interval)
	defer ticker.Stop()
	
	for {
		select {
		case <-ticker.C:
			hc.checkEndpoints()
		case <-hc.shutdown:
			return
		}
	}
}

// checkEndpoints checks health of all endpoints
func (hc *HealthChecker) checkEndpoints() {
	for _, endpoint := range hc.endpoints {
		go hc.checkEndpoint(endpoint)
	}
}

// checkEndpoint checks health of a single endpoint
func (hc *HealthChecker) checkEndpoint(endpoint *Endpoint) {
	ctx, cancel := context.WithTimeout(context.Background(), hc.timeout)
	defer cancel()
	
	req, _ := http.NewRequestWithContext(ctx, "GET", endpoint.URL+"/health", nil)
	
	startTime := time.Now()
	resp, err := http.DefaultClient.Do(req)
	latency := time.Since(startTime)
	
	if err != nil || resp.StatusCode != http.StatusOK {
		endpoint.Healthy = false
	} else {
		endpoint.Healthy = true
		endpoint.AvgLatency = (endpoint.AvgLatency + latency) / 2
	}
	
	endpoint.LastCheck = time.Now()
	
	if resp != nil {
		resp.Body.Close()
	}
}

// Stop stops health checking
func (hc *HealthChecker) Stop() {
	close(hc.shutdown)
	hc.wg.Wait()
}

// GetMetrics returns performance metrics
func (o *PerformanceOptimizer) GetMetrics() map[string]interface{} {
	o.metrics.mu.RLock()
	defer o.metrics.mu.RUnlock()
	
	metrics := map[string]interface{}{
		"connections": map[string]interface{}{
			"created": o.metrics.ConnectionsCreated,
			"reused":  o.metrics.ConnectionsReused,
			"closed":  o.metrics.ConnectionsClosed,
			"avg_age": o.metrics.AvgConnectionAge.String(),
		},
		"compression": map[string]interface{}{
			"ratio":             o.metrics.CompressionRatio,
			"compression_time":  o.metrics.CompressionTime.String(),
			"decompression_time": o.metrics.DecompressionTime.String(),
		},
		"performance": map[string]interface{}{
			"avg_response_time": o.metrics.AvgResponseTime.String(),
			"p95_response_time": o.metrics.P95ResponseTime.String(),
			"p99_response_time": o.metrics.P99ResponseTime.String(),
			"throughput":        o.metrics.Throughput,
		},
	}
	
	if o.poolManager != nil {
		metrics["pool"] = map[string]interface{}{
			"current_connections": atomic.LoadInt32(&o.poolManager.currentConns),
			"active_connections":  atomic.LoadInt32(&o.poolManager.activeConns),
			"pool_hits":          atomic.LoadInt64(&o.poolManager.poolHits),
			"pool_misses":        atomic.LoadInt64(&o.poolManager.poolMisses),
		}
	}
	
	if o.compressionHandler != nil {
		o.compressionHandler.mu.RLock()
		metrics["compression_stats"] = map[string]interface{}{
			"total_compressed":   o.compressionHandler.totalCompressed,
			"total_uncompressed": o.compressionHandler.totalUncompressed,
			"bytes_before":       o.compressionHandler.bytesBeforeComp,
			"bytes_after":        o.compressionHandler.bytesAfterComp,
			"avg_ratio":          o.compressionHandler.avgCompressionRatio,
		}
		o.compressionHandler.mu.RUnlock()
	}
	
	if o.loadBalancer != nil {
		endpoints := make([]map[string]interface{}, 0)
		for _, ep := range o.loadBalancer.endpoints {
			endpoints = append(endpoints, map[string]interface{}{
				"url":            ep.URL,
				"healthy":        ep.Healthy,
				"active_conns":   atomic.LoadInt32(&ep.ActiveConns),
				"total_requests": atomic.LoadInt64(&ep.TotalRequests),
				"avg_latency":    ep.AvgLatency.String(),
			})
		}
		metrics["endpoints"] = endpoints
	}
	
	return metrics
}

// Close shuts down the performance optimizer
func (o *PerformanceOptimizer) Close() error {
	if o.loadBalancer != nil && o.loadBalancer.healthChecker != nil {
		o.loadBalancer.healthChecker.Stop()
	}
	
	return nil
}